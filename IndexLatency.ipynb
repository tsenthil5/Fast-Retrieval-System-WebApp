{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db81fcdc-acf4-433a-a83b-941a58d9c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b846e6-d73c-419c-895b-d253dc9e02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index('faissImageVector1M.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63a5cab-6ca4-4bce-8bfa-846ea8c7421b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998934"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = []\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4cde9c-615d-46d3-814f-683db2bc7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(index.ntotal):\n",
    "    # print(type((index.reconstruct(i))))\n",
    "    # print(len((index.reconstruct(i))))\n",
    "    vectors.append(index.reconstruct(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c27c502-7d12-4845-9261-39b0449198a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998934, 768)\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "len(vectors)\n",
    "vectors = np.array(vectors)\n",
    "print(vectors.shape)\n",
    "print(type(vectors[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a930a87b-13b0-45e1-baa5-8adf3236f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d036c853-79e4-4a4e-8690-69ea2ba360ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create IndexFlatL2: 1.46 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "index_flatl2 = faiss.IndexFlatL2(vectors.shape[1])\n",
    "index_flatl2.add(vectors)\n",
    "print(\"Time taken to create IndexFlatL2: %.2f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6239731d-e169-4527-bdf8-d6c7bb5908d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create IndexIVFFlat: 19.24 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Now we want to convert this to an IndexIVFFlat index\n",
    "# First, we need to train a quantizer\n",
    "nlist = 1000 # number of Voronoi cells (i.e., clusters)\n",
    "kmeans = faiss.Kmeans(vectors.shape[1], nlist)\n",
    "kmeans.train(vectors)\n",
    "\n",
    "# Use the centroids of the clusters as the quantizer\n",
    "quantizer = faiss.IndexFlatL2(vectors.shape[1])\n",
    "quantizer.add(kmeans.centroids)\n",
    "\n",
    "# Create an IndexIVFFlat index with the trained quantizer\n",
    "index_ivfflat = faiss.IndexIVFFlat(quantizer, vectors.shape[1], nlist)\n",
    "\n",
    "# Train the index\n",
    "# assert not index_ivfflat.is_trained\n",
    "index_ivfflat.train(vectors)\n",
    "# assert index_ivfflat.is_trained\n",
    "\n",
    "# Add vectors to the index\n",
    "index_ivfflat.add(vectors)\n",
    "\n",
    "# Print the time taken to create the IndexIVFFlat index\n",
    "print(\"Time taken to create IndexIVFFlat: %.2f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d28211-efbd-4956-9702-aea5de87f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'index' is your IndexIVFFlat index\n",
    "# faiss.write_index(index_ivfflat, 'Image1000IVF.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66c4534-1a5d-4f94-9616-bf85c6bce990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "Imagemodel = AutoModel.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "processor = AutoProcessor.from_pretrained(\"google/siglip-base-patch16-224\", low_cpu_mem_usage=True, do_rescale=False)\n",
    "device_type = \"cpu\"\n",
    "device = torch.device(device_type)\n",
    "Imagemodel.to(device)\n",
    "path = \"static/images/3637013_c675de7705.jpg\"\n",
    "newImage = Image.open(path)\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((300, 300)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "inputs = transform(newImage)\n",
    "inputs = (inputs - inputs.min()) / (inputs.max() - inputs.min())\n",
    "inputs = processor(images=inputs, return_tensors=\"pt\").to(device)\n",
    "features = Imagemodel.get_image_features(**inputs)\n",
    "features = np.array(features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdd2ba5f-9c8e-46e0-8410-66e144606480",
   "metadata": {},
   "outputs": [],
   "source": [
    "features\n",
    "del Imagemodel\n",
    "del processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cfd17dc-02c9-463d-957b-0df79e642dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 48.6658 seconds\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'vectors' is your list of vectors and 'query' is your query vector\n",
    "# vectors = np.array(vectors)\n",
    "# query = np.array(query)\n",
    "\n",
    "# Calculate the start time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Calculate the distance between the query and each vector\n",
    "distances = np.linalg.norm(vectors - features, axis=1)\n",
    "\n",
    "# Get the indices of the K smallest distances\n",
    "K = 100000  # Change this to the number of similar images you want to retrieve\n",
    "indices = np.argpartition(distances, K)[:K]\n",
    "\n",
    "# Calculate the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the time taken\n",
    "print(\"Time taken: %.4f seconds\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ccf9c-83df-4cd1-8658-999dc0d79669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
